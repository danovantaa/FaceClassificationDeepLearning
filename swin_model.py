# -*- coding: utf-8 -*-
"""Swin Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oKdbWr3p-F2SAYZkXIWANZQECwwR_CG9
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os

zip_path = "/content/drive/MyDrive/Dataset/datasetDL.zip"
extract_path = "/content/dataset"

with zipfile.ZipFile(zip_path, 'r') as z:
    z.extractall(extract_path)

print("Dataset berhasil diekstrak ke:", extract_path)

!ls /content/dataset

import os

for root, dirs, files in os.walk("/content/dataset"):
    print("ROOT:", root)
    print("DIRS:", dirs)
    print("FILES:", files)
    print("-" * 50)

import os, shutil

src = "/content/dataset/Train"
dst = "/content/dataset"


for folder in os.listdir(src):
    folder_path = os.path.join(src, folder)


    if folder == ".DS_Store":
        continue

    shutil.move(folder_path, os.path.join(dst, folder))
    print("Pindah:", folder)

print("\nSEMUA FOLDER MAHASISWA SELESAI DIPINDAHKAN!")

import shutil
shutil.rmtree("/content/dataset/Train")

print("Folder 'Train' sudah dihapus!")

import os
print(os.listdir("/content/dataset"))

import os
from PIL import Image

root = "/content/dataset"
count = 0
failed = []

for folder, subdirs, files in os.walk(root):
    for file in files:
        if file.lower().endswith(".webp"):
            src = os.path.join(folder, file)
            dst = src.rsplit(".", 1)[0] + ".jpg"
            try:
                img = Image.open(src).convert("RGB")
                img.save(dst, "JPEG", quality=95)
                print("OK:", file)
                count += 1
            except Exception as e:
                print("GAGAL:", src, e)
                failed.append(src)

print("\nTOTAL WEBP → JPG:", count)
print("GAGAL:", len(failed))

import os

root = "/content/dataset"
webps = []

for folder, subdirs, files in os.walk(root):
    for f in files:
        if f.lower().endswith(".webp"):
            webps.append(os.path.join(folder, f))

print("Jumlah file .webp ditemukan:", len(webps))
for w in webps:
    print(w)

import os
import shutil

bad = "/content/dataset/Nasya Aulia Efendi/temp_image_5BD313DA-028B-4E44-92B4-98405A6C90DA - NASYA AULIA EFENDI.webp"

if os.path.exists(bad):
    os.makedirs("/content/dataset/INVALID_FILES", exist_ok=True)
    shutil.move(bad, "/content/dataset/INVALID_FILES/")
    print("File corrupt dipindahkan ke folder INVALID_FILES")
else:
    print("File tidak ditemukan")

import os

base = "/content/dataset"

for cls in os.listdir(base):
    path = os.path.join(base, cls)
    if os.path.isdir(path) and cls != "INVALID_FILES":
        print(cls, "=", len(os.listdir(path)), "gambar")

import os

root = "/content/dataset/Train"
webps = []

for folder, subdirs, files in os.walk(root):
    for f in files:
        if f.lower().endswith(".webp"):
            webps.append(os.path.join(folder, f))

print("Jumlah file .webp tersisa:", len(webps))
webps[:10]

!find /content/dataset -name ".DS_Store" -delete

from torchvision import datasets, transforms

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

dataset_path = "/content/dataset"
full_dataset = datasets.ImageFolder(dataset_path, transform=transform)

num_classes = len(full_dataset.classes)
print("Jumlah kelas:", num_classes)
print("Daftar kelas (10 pertama):", full_dataset.classes[:10])

from torch.utils.data import random_split, DataLoader

total = len(full_dataset)
train_size = int(0.7 * total)
val_size = int(0.15 * total)
test_size = total - train_size - val_size

train_ds, val_ds, test_ds = random_split(full_dataset, [train_size, val_size, test_size])

train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=16)
test_loader = DataLoader(test_ds, batch_size=16)

print("Train =", len(train_ds))
print("Validation =", len(val_ds))
print("Test =", len(test_ds))

import torch
import torch.nn as nn
import timm

device = "cuda" if torch.cuda.is_available() else "cpu"

model = timm.create_model(
    "swin_base_patch4_window7_224",
    pretrained=True,
    num_classes=num_classes
)

model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

import shutil
import os

src = "/content/dataset/INVALID_FILES"
dst = "/content/bad_files"

if os.path.exists(src):
    shutil.move(src, dst)
    print("INVALID_FILES dipindahkan ke:", dst)
else:
    print("Folder INVALID_FILES tidak ditemukan.")

!ls /content/dataset

!ls /content/dataset

from torchvision import datasets, transforms

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

dataset_path = "/content/dataset"
full_dataset = datasets.ImageFolder(dataset_path, transform=transform)

print("Jumlah kelas:", len(full_dataset.classes))
print("Contoh kelas:", full_dataset.classes[:10])

from torch.utils.data import random_split, DataLoader

total = len(full_dataset)
train_size = int(0.7 * total)
val_size = int(0.15 * total)
test_size = total - train_size - val_size

train_ds, val_ds, test_ds = random_split(full_dataset, [train_size, val_size, test_size])

train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=16)
test_loader = DataLoader(test_ds, batch_size=16)

print("Train =", len(train_ds))
print("Validation =", len(val_ds))
print("Test =", len(test_ds))

!pip install timm

import os
import shutil
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
from torchvision import transforms, datasets
import timm

invalid = "/content/dataset/INVALID_FILES"
if os.path.exists(invalid):
    shutil.rmtree(invalid)
print("INVALID_FILES folder removed.")

import os

for root, dirs, files in os.walk("/content"):
    print(root)
    break

import os

print("Isi folder /content:")
print(os.listdir("/content"))

if os.path.exists("/content/dataset"):
    print("\nIsi folder /content/dataset:")
    print(os.listdir("/content/dataset"))

data_dir = "/content/dataset"

from torchvision import transforms

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5],
                         [0.5, 0.5, 0.5])
])

from torchvision import datasets

dataset = datasets.ImageFolder(root=data_dir, transform=transform)

print("Jumlah kelas:", len(dataset.classes))
print("Contoh kelas:", dataset.classes[:10])

!pip install timm

import os
import shutil
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
from torchvision import transforms, datasets
import timm

data_dir = "/content/dataset"

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5],
                         [0.5, 0.5, 0.5])
])

dataset = datasets.ImageFolder(root=data_dir, transform=transform)

num_classes = len(dataset.classes)
print("Jumlah kelas:", num_classes)

train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size

train_set, val_set = random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_set, batch_size=16, shuffle=True)
val_loader = DataLoader(val_set, batch_size=16, shuffle=False)

model = timm.create_model(
    'swin_tiny_patch4_window7_224',
    pretrained=True,
    num_classes=num_classes
)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

epochs = 10
train_losses = []
train_accs = []

for epoch in range(epochs):
    model.train()
    running_loss = 0
    correct = 0
    total = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)

        loss = criterion(outputs, labels)
        running_loss += loss.item()

        loss.backward()
        optimizer.step()

        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    train_loss = running_loss / len(train_loader)
    train_acc = correct / total

    train_losses.append(train_loss)
    train_accs.append(train_acc)

    print(f"Epoch {epoch+1}/{epochs} | Loss: {train_loss:.4f} | Acc: {train_acc:.4f}")

epochs = 10

train_losses = []
train_accs = []
val_losses = []
val_accs = []

for epoch in range(epochs):
    # ===================== TRAIN =====================
    model.train()
    running_loss = 0
    correct = 0
    total = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)

        loss = criterion(outputs, labels)
        running_loss += loss.item()

        loss.backward()
        optimizer.step()

        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    train_loss = running_loss / len(train_loader)
    train_acc = correct / total

    train_losses.append(train_loss)
    train_accs.append(train_acc)

    # ===================== VALIDATION =====================
    model.eval()
    val_running_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            val_running_loss += loss.item()

            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    val_loss = val_running_loss / len(val_loader)
    val_acc = correct / total

    val_losses.append(val_loss)
    val_accs.append(val_acc)

    print(f"Epoch {epoch+1}/{epochs} | "
          f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | "
          f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")

import torch
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np


model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in val_loader:
        images = images.to(device)
        outputs = model(images)

        _, preds = torch.max(outputs, 1)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.numpy())


cm = confusion_matrix(all_labels, all_preds, labels=list(range(len(dataset.classes))))

plt.figure(figsize=(25, 25))
sns.heatmap(cm, annot=False, cmap="Blues")

plt.title("Confusion Matrix (70 Classes)")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.tight_layout()
plt.savefig("confusion_matrix.png")
plt.show()

print("Confusion matrix saved!")

import matplotlib.pyplot as plt


train_accs = [0.9956,0.9956,1.0,0.9912,1.0,1.0,0.9956,1.0,0.9912,0.9956]
val_accs   = [0.5088,0.5088,0.4912,0.5088,0.4912,0.4912,0.5088,0.4912,0.5088,0.5088]

train_losses = [0.0652,0.0536,0.0506,0.0603,0.0461,0.0281,0.0371,0.0387,0.1442,0.0296]
val_losses   = [2.4828,2.5155,2.7010,2.5902,2.6085,2.6041,2.6143,2.6383,2.5756,2.6439]

epochs = range(1, 11)


plt.figure(figsize=(8,5))
plt.plot(epochs, train_accs, label='Train Accuracy')
plt.plot(epochs, val_accs, label='Validation Accuracy')
plt.title('Training vs Validation Accuracy (Swin)')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid()
plt.show()


plt.figure(figsize=(8,5))
plt.plot(epochs, train_losses, label='Train Loss')
plt.plot(epochs, val_losses, label='Validation Loss')
plt.title('Training vs Validation Loss (Swin)')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()

torch.save(model.state_dict(), "swin_model.pth")

print("Model Swin berhasil disimpan!")

import os

if os.path.exists("swin_model.pth"):
    print("File model ditemukan ✅")
else:
    print("File model TIDAK ditemukan ❌")

import torch
import timm
import os
import matplotlib.pyplot as plt
from torchvision import transforms
from PIL import Image
import math

# ================== SETTING ==================
test_dir = "dataset"
model_path = "swin_model.pth"
img_size = 224
max_images = 70

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ================== LOAD DATA ==================
class_names = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])
num_classes = len(class_names)

print("Jumlah class:", num_classes)

# ================== LOAD MODEL ==================
model = timm.create_model(
    'swin_tiny_patch4_window7_224',
    pretrained=False,
    num_classes=num_classes
)

model.load_state_dict(torch.load(model_path, map_location=device))
model.to(device)
model.eval()

print("✅ Model loaded")

# ================== TRANSFORM ==================
transform = transforms.Compose([
    transforms.Resize((img_size, img_size)),
    transforms.ToTensor()
])

# ================== AMBIL GAMBAR ==================
image_list = []

for idx, name in enumerate(class_names):
    person_dir = os.path.join(test_dir, name)

    for img_name in os.listdir(person_dir):
        if img_name.endswith(('.jpg', '.jpeg', '.png')):
            image_list.append((os.path.join(person_dir, img_name), name))
    if len(image_list) >= max_images:
        break

print(f"Total images loaded: {len(image_list)}")

# ================== PREDIKSI & PLOT ==================
cols = 7
rows = math.ceil(len(image_list) / cols)

plt.figure(figsize=(20, 20))
plt.suptitle(f"All Validation Samples ({len(image_list)} shown)", fontsize=20)

for i, (img_path, true_label) in enumerate(image_list):
    img = Image.open(img_path).convert("RGB")
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(img_tensor)
        _, pred = torch.max(output, 1)

    pred_label = class_names[pred.item()]

    plt.subplot(rows, cols, i+1)
    plt.imshow(img)
    plt.axis("off")

    # Warna teks
    color = "green" if pred_label == true_label else "red"

    plt.title(
        f"True: {true_label}\nPred: {pred_label}",
        fontsize=9,
        color=color
    )

plt.tight_layout()
plt.savefig("swin_prediction_grid.png")
plt.show()

